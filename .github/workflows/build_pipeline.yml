# This workflow will install Python dependencies, run tests and lint with a single version of Python
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: DiyDogExtractor Build and Run tests

on:
  workflow_dispatch :
    inputs:
      upload_db:
        description: 'Diydog extracted Database upload (as an artifact) to Github artifacts registry'
        required: true
        default: false
        type: boolean

  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read
  id-token: 'write'

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.11
      uses: actions/setup-python@v3
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r Sources/requirements.txt

    # Tests shall pass before continuing !
    - name: Test with pytest
      run: |
        pytest Sources --junit-xml=Sources/.cache/test_results.xml
      continue-on-error: false

    # - name: Test Report
    #   uses: dorny/test-reporter@v1
    #   if: success() || failure()                 # run this step even if previous step failed
    #   with:
    #     name: Pytest results                      # Name of the check run which will be created
    #     path: Sources/.cache/test_results.xml    # Path to test results
    #     reporter: jest-junit                     # Format of test results

    - name: Archive Test Results
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: Sources/.cache/test_results.xml

    - name : run DiyDog extraction services
      run : |
        ./round_trip.sh

      # Now it's uploading logs
    - name: Archive extraction session logs
      uses: actions/upload-artifact@v3
      with:
        name: extraction_session_logs
        path: Sources/.cache/logs.txt

    - name : Zip extracted database
      run : |
        pushd Sources/.cache
        zip -r diydog-db.zip deployed/
        popd

    # Now it's time to upload the newly built database
    - name: Archive extracted database for diydog book
      uses: actions/upload-artifact@v3
      if: github.event.inputs.upload_db == true
      with:
        name: diydogExtractedDB
        path: Sources/.cache/diydog-db.zip

    # Push images to google cloud
    - id: 'auth'
      uses: 'google-github-actions/auth@v1'
      with:
        #workload_identity_provider: 'projects/123456789/locations/global/workloadIdentityPools/my-pool/providers/my-provider'
        credentials_json: ${{ secrets.DRUIDS_CORNER_CLOUD_DBPUBLISHER_KEYFILE }}
        service_account: ${{ secrets.DRUIDS_CORNER_CLOUD_DBPUBLISHER_SA }}

    # Push database to gcloud bucket !
    - id: 'upload-file'
      uses: 'google-github-actions/upload-cloud-storage@v1'
      with:
        path: 'Sources/.cache/diydog-db.zip'
        destination: '${{ secrets.DRUIDS_CORNER_CLOUD_BUCKET_NAME }}/DiyDogExtracted'


